{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "ninf = -1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def read_data(path, column=0):\n",
    "    \"\"\"column=0 means input sequence, column=1 means label\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    data = []\n",
    "    sample = []\n",
    "    \n",
    "    for line in lines:\n",
    "        formatted_line = line.strip()\n",
    "        \n",
    "        if len(formatted_line) > 0:\n",
    "            split_data = formatted_line.split(\" \")\n",
    "            sample.append(split_data[column])\n",
    "\n",
    "        else:\n",
    "            data.append(sample)\n",
    "            sample = []\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "full_dir = Path('full')\n",
    "partial_dir = Path('partial')\n",
    "\n",
    "x_data, y_data = read_data(partial_dir/'train', 0), read_data(partial_dir/'train', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 700)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of instances in the dataset\n",
    "len(x_data), len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-art',\n",
       " 'B-gpe',\n",
       " 'I-org',\n",
       " 'B-nat',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'O',\n",
       " 'I-gpe',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'I-tim',\n",
       " 'I-art',\n",
       " 'B-per',\n",
       " 'I-per',\n",
       " 'B-tim',\n",
       " 'B-org']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y labels\n",
    "y_vocab = list(set([oo for o in y_data for oo in o])); y_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4068"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x vocab\n",
    "x_vocab = list(set([oo for o in x_data for oo in o])); len(x_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Part I (i): Emission scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def calc_e(x_data, y_data, x_vocab, y_vocab):\n",
    "    count_emission = Counter([(x,y) for x_instance, y_instance in zip(x_data, y_data) for x, y in zip(x_instance, y_instance)])\n",
    "    count_label = Counter([oo for o in y_data for oo in o])\n",
    "    \n",
    "    e_score = {}\n",
    "    for y in y_vocab:\n",
    "        for x in x_vocab:\n",
    "            feature = f\"emission:{y}+{x}\"\n",
    "            \n",
    "            if (x,y) not in count_emission:\n",
    "                e_score[feature] = ninf\n",
    "            else:\n",
    "                score = np.log(count_emission[(x,y)]  /  count_label[y])\n",
    "                e_score[feature] = score\n",
    "    \n",
    "    return e_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "emission_dict = calc_e(x_data, y_data, x_vocab, y_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Part I (ii): Transition scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def calc_t(y_data, y_vocab):\n",
    "    count_transition = Counter([ (y_prev, y) for y_instance in y_data for y_prev, y in zip(['START'] + y_instance, y_instance + ['STOP'])])\n",
    "    count_label = Counter([y for y_instance in y_data for y in ['START'] + y_instance])\n",
    "    \n",
    "    f_score = {}\n",
    "    for y_prev in ['START'] + y_vocab:\n",
    "        for y in y_vocab + ['STOP']:\n",
    "            feature = f\"transition:{y_prev}+{y}\"\n",
    "            \n",
    "            if (y_prev,y) not in count_transition:\n",
    "                f_score[feature] = ninf\n",
    "            else:\n",
    "                score = np.log(count_transition[(y_prev,y)]  /  count_label[y_prev])\n",
    "                f_score[feature] = score\n",
    "    \n",
    "    return f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "transition_dict = calc_t(y_data, y_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "feature_dict = {**transition_dict, **emission_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Part II (i): Compute Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def compute_score(x_instance, y_instance, feature_dict):\n",
    "    feature_count = defaultdict(int)\n",
    "    \n",
    "    for x, y in zip(x_instance, y_instance): feature_count[f\"emission:{y}+{x}\"] += 1\n",
    "    \n",
    "    for y_prev, y in zip(['START'] + y_instance, y_instance + ['STOP']):\n",
    "        feature_count[f\"transition:{y_prev}+{y}\"] += 1\n",
    "        \n",
    "    score = sum([feature_dict[feat]*count for feat, count in feature_count.items()])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-139.57175855522826"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_instance = \"This is the second U.N.-Congolese offensive against militias in the region since the DRC 's constitutional referendum a week ago .\".split()\n",
    "y_instance = 'O O O O O O O O O O O O O B-geo O O O O O O O'.split()\n",
    "compute_score(x_instance, y_instance, feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Part II (ii): Viterbi decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TODO: \n",
    "how to evaluate using conlleval.evaluate function\n",
    "\n",
    "do evaluation on the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O O O O O O O O O O O O B-geo O O O O O O O\n",
      "O O O O O O O O O O O O O B-geo O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "def viterbi(x_instance, y_vocab, feature_dict):\n",
    "    n, d = len(x_instance), len(y_vocab)\n",
    "    scores = np.full( (n,d), ninf)\n",
    "    bp = np.full( (n,d), 0, dtype=np.int)\n",
    "    \n",
    "    for i, y in enumerate(y_vocab):\n",
    "        t_score = feature_dict.get( f\"transition:START+{y}\",  ninf)\n",
    "        e_score = feature_dict.get( f\"emission:{y}+{x_instance[0]}\",  ninf)\n",
    "        scores[0, i] = t_score + e_score\n",
    "        \n",
    "    for i in range(1, n):\n",
    "        for y_i, y in enumerate(y_vocab):\n",
    "            for y_prev_i, y_prev in enumerate(y_vocab):\n",
    "                t_score = feature_dict.get( f\"transition:{y_prev}+{y}\", ninf)\n",
    "                e_score = feature_dict.get( f\"emission:{y}+{x_instance[i]}\", ninf)\n",
    "                score = t_score + e_score + scores[i-1, y_prev_i]\n",
    "                if score > scores[i, y_i]:\n",
    "                    scores[i, y_i] = score\n",
    "                    bp[i, y_i] = y_prev_i\n",
    "    \n",
    "    final_score, final_bp = ninf, 0\n",
    "    for i, y_prev in enumerate(y_vocab):\n",
    "        t_score = feature_dict.get( f\"transition:{y_prev}+STOP\", ninf)\n",
    "        score = t_score + scores[n-1, i]\n",
    "        if score > final_score: \n",
    "            final_score = score\n",
    "            final_bp = i\n",
    "            \n",
    "    decoded_sequence = [ y_vocab[final_bp], ]\n",
    "    for i in range(n-1, 0, -1):\n",
    "        final_bp = bp[i, final_bp]\n",
    "        decoded_sequence = [ y_vocab[final_bp] ] + decoded_sequence\n",
    "        \n",
    "    return decoded_sequence\n",
    "\n",
    "print(\" \".join(viterbi(x_instance, y_vocab, feature_dict)),)\n",
    "print(\" \".join(y_instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Part III (i): CRF loss\n",
    "refer to [machine learning slides](https://drive.google.com/file/d/1RfPcnQigx4jdLtnTjjjI1Jgd2UufexhV/view?usp=sharing) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def logsumexp(a):\n",
    "    if np.sum(a) > 100:\n",
    "        b = a.max()\n",
    "        return b + np.log( (np.exp(a-b)).sum() )\n",
    "    if np.exp(a).sum() < 1e-100:\n",
    "        return ninf\n",
    "    else:\n",
    "        return np.log( np.exp(a).sum() )\n",
    "\n",
    "def forward(x_instance, y_vocab, feature_dict):\n",
    "    n, d = len(x_instance), len(y_vocab)\n",
    "    scores = np.full( (n,d), ninf)\n",
    "    \n",
    "    for i, y in enumerate(y_vocab):\n",
    "        t_score = feature_dict.get( f\"transition:START+{y}\", ninf)\n",
    "        scores[0, i] = t_score\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        for y_i, y in enumerate(y_vocab):\n",
    "            temp = np.full( (d,), ninf)\n",
    "            for y_prev_i, y_prev in enumerate(y_vocab):\n",
    "                t_score = feature_dict.get( f\"transition:{y_prev}+{y}\", ninf)\n",
    "                e_score = feature_dict.get( f\"emission:{y_prev}+{x_instance[i-1]}\", ninf)\n",
    "                temp[y_prev_i] = e_score + t_score + scores[i-1, y_prev_i]\n",
    "            scores[i, y_i] = logsumexp(temp)\n",
    "    \n",
    "    temp = np.full( (d,), ninf)\n",
    "    for i, y_prev in enumerate(y_vocab):\n",
    "        t_score = feature_dict.get( f\"transition:{y_prev}+STOP\", ninf)\n",
    "        e_score = feature_dict.get( f\"emission:{y_prev}+{x_instance[-1]}\", ninf)\n",
    "        temp[i] = e_score + t_score + scores[-1, i]\n",
    "    alpha = logsumexp(temp)\n",
    "    \n",
    "    return scores, alpha\n",
    "\n",
    "def loss_fn(x_instance, y_instance, feature_dict, y_vocab):\n",
    "    first_term = compute_score(x_instance, y_instance, feature_dict)\n",
    "    _, forward_score = forward(x_instance, y_vocab, feature_dict)\n",
    "    return forward_score - first_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3302877199753311"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(x_instance, y_instance, feature_dict, y_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Part III (ii): forward backward for gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def backward(x_instance, y_vocab, feature_dict):\n",
    "    n, d = len(x_instance), len(y_vocab)\n",
    "    scores = np.full( (n,d), ninf)\n",
    "    \n",
    "    for i, y in enumerate(y_vocab):\n",
    "        t_score = feature_dict.get( f\"transition:{y}+STOP\", ninf)\n",
    "        e_score = feature_dict.get( f\"emission:{y}+{x_instance[-1]}\", ninf)\n",
    "        scores[-1, j] = t_score + e_score\n",
    "        \n",
    "    for i in range(n-1, 0, -1):\n",
    "        for y_i, y in enumerate(y_vocab):\n",
    "            temp = np.full( (d,), ninf)\n",
    "            for y_next_i, y_next in enumerate(y_vocab):\n",
    "                t_score = feature_dict.get( f\"transition:{y}+{y_next}\", ninf)\n",
    "                e_score = feature_dict.get( f\"emission:{y}+{x_instance[i-1]}\")\n",
    "                temp[y_next_i] = e_score + t_score + scores[i, y_next_i]\n",
    "            scores[i-1, k] = logsumexp(temp)\n",
    "            \n",
    "    temp = np.full( (d,), ninf)\n",
    "    for i, y_next in enumerate(y_vocab):\n",
    "        t_score = feature_dict.get( f\"transition:START+{y_next}\")\n",
    "        temp[i] = t_score + scores[0, i]\n",
    "    beta = logsumexp(temp)\n",
    "    \n",
    "    return scores, beta\n",
    "\n",
    "\n",
    "\n",
    "def forward_backward(x_instance, y_vocab, feature_dict):\n",
    "    n, d = len(x_instance), len(y_vocab)\n",
    "    f_scores, alpha = forward(x_instance, y_vocab, feature_dict)\n",
    "    b_scores, beta = backward(x_instance, y_vocab, feature_dict)\n",
    "    \n",
    "    feature_expected_count = defaultdict(float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for y_i, y in enumerate(y_vocab):\n",
    "            e_feature = f\"emission:{y}+{x_instance[i]}\"\n",
    "            feature_expected_count[e_feature] += f_scores[i, y_i] + b_scores[i, y_i] - alpha # TODO: here do we need to add exp?\n",
    "            \n",
    "    for i, y_next in enumerate(y_vocab):\n",
    "        t_feature = f\"transition:START+{y_next}\"\n",
    "        feature_expected_count[t_feature] += f_scores[0, i] + b_scores[0, i] - alpha\n",
    "        \n",
    "        t_feature = f\"transition:{y_next}+STOP\"\n",
    "        feature_expected_count[t_feature] += f_scores[-1, i] + b_scores[-1, i] - alpha\n",
    "        \n",
    "    for y_i, y in enumerate(y_vocab):\n",
    "        for y_next_i, y_next in enumerate(y_vocab):\n",
    "            t_feature = f\"transition:{y}+{y_next}\"\n",
    "            total = 0\n",
    "            for i in range(n-1):\n",
    "                total += f_scores[i, y_i] + b_scores[i, y_i] - alpha # TODO: here do we need to include transition and emission scores?\n",
    "            feature_expected_count[t_feature] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
